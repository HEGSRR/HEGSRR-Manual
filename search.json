[{"path":"index.html","id":"reproducible-research-compendia-and-workflows","chapter":"Reproducible research compendia and workflows","heading":"Reproducible research compendia and workflows","text":"Introduction paragraphOther analogous reproducibility infrastructure projects include:TIER protocol: https://www.projecttier.org/tier-protocol/protocol-4-0/Social Science Reproduction Platform https://www.socialsciencereproduction.org/ Guide Accelerating Computational Reproducibility Social Sciences: https://bitss.github.io/ACRE/WORCS workflow open reproducible code science https://cjvanlissa.github.io/worcs/","code":""},{"path":"index.html","id":"open-science-reproducibility-and-replicability","chapter":"Reproducible research compendia and workflows","heading":"Open science, reproducibility and replicability","text":"Theoretical foundation open science practices … discovering valid generalizable knowledge.Open science …Mertonian norms (1942) (christensen et al pg 23)“Replication methodological tool based reptition procedure invovled establishing fact, truth, piece knowledge.” (Schmidt 20019)Reproducibility … original study may considered computationally reproducible … reproduction study…Replicability … replication study…(Christensen et al pg 159)","code":""},{"path":"index.html","id":"pragmatic-principles-for-designing-reproducible-research-workflows","chapter":"Reproducible research compendia and workflows","heading":"Pragmatic principles for designing reproducible research workflows","text":"decide construct research template workflow?followed principles making design decisions:Efficiency individual researchers research teamsFlexibility accommodate many types researchTransparency provenance level individual research artefacts overall research designCompatibility research standardsFAIR dataLower transaction costsEase appropriate citation research products","code":""},{"path":"index.html","id":"efficiency","chapter":"Reproducible research compendia and workflows","heading":"Efficiency","text":"Individual tasks start take time, especially first, long-term, amount time effort put research project inception publishing save effort. particular, researchers start reap dividends need revise research, verify methodology results publication, revise correct errors early research workflow. Adopting reproducible research practices also reduces transaction costs pausing research project (e.g. field season heavy teaching semester) restarting later.Reduce inefficiencies research teams, especially teams distributed space (different research labs home field) time (e.g. shifting composition research team students come go program)","code":""},{"path":"index.html","id":"flexibility","chapter":"Reproducible research compendia and workflows","heading":"Flexibility","text":"diversity geographycomplexity heterogeneity phenomena (NASEM complexity ; precision replication)just computational geography - qualitative mixed methods research welloriginal studies, meta-analyses, reproductions, replicationsability fork reproduction replication","code":""},{"path":"index.html","id":"transparency-and-provenance","chapter":"Reproducible research compendia and workflows","heading":"Transparency and Provenance","text":"applies individual research products, e.g. data, code, resulting figures tablesalso applies overall research project terms research design, suggesting need pre-analysis registrations, tracking changes research design","code":""},{"path":"index.html","id":"ethics-and-privacy","chapter":"Reproducible research compendia and workflows","heading":"Ethics and Privacy","text":"research workflow template must account appropriate steps protect privacy human subjects adhere standards (Institutional review boards (IRB) / independent ethics committees (IEC) / etc.) reviews responsible ethical research.","code":""},{"path":"index.html","id":"compatibility","chapter":"Reproducible research compendia and workflows","heading":"Compatibility","text":"OSF, journal & funding agency requirements, standardized metadatafacilitates convergence research interoperable disciplines","code":""},{"path":"index.html","id":"fair-data","chapter":"Reproducible research compendia and workflows","heading":"FAIR Data","text":"FAIR principles findability, accessibility, interoperability, reusabilityopen standards (data formats)licensingmetadata documented open standards","code":""},{"path":"index.html","id":"transaction-costs","chapter":"Reproducible research compendia and workflows","heading":"Transaction costs","text":"economic definition transaction costs, maximizing legibility codified knowledge.Maximizing efficiency transparency research communication re-use / extensibility, researchers students.FAIR principles findability, accessibility, interoperability, reusability FAIR data contribute substantially reducing transaction costs researchers computer algorithms access use research project. However additionadherence common organizational structure/template research compendium (think principles communication education– standardize format & structure much possible)open source softwarecomputational environmentlegible codemodularity","code":""},{"path":"index.html","id":"citation","chapter":"Reproducible research compendia and workflows","heading":"Citation","text":"work easily reusable extensible, want credit .\nDOI’s, Citation file Git Repository, possibly DOI particular artefacts anticipate citing .\nCross-linking different research products project becomes living ecosystem research components.","code":""},{"path":"index.html","id":"organization-structure-of-this","chapter":"Reproducible research compendia and workflows","heading":"Organization / Structure of this","text":"Template recommended contentResearch workflow recommended actionsWe organize manual follow research workflow recommended actions, including actions interacting , creating editing research compendium.follow open science workflow composed steps :ProvocationIdeationData observation curation (“Knowledge Generation” NASEM 2018)ValidationDisseminationPreservation","code":""},{"path":"provocation.html","id":"provocation","chapter":"1 Provocation","heading":"1 Provocation","text":"enter provocation phase? Interest topic…Framework discovering proving causal mechanisms, extending consider types research questions motivations extensions, reanalyses, replications, reproductions.\nInclude exploratory analysis case studies type research.Reference: www.edreplication.org","code":""},{"path":"provocation.html","id":"literature-review","chapter":"1 Provocation","heading":"1.1 Literature review","text":"create bibtex file manuscriptbeyond manuscripts: pay attention references software, code, data, supplementary materialsuse reference manager collect references ease bibtex generationtake notes search date, keywords, etc.include preprintsliterature reviews become powerful open science","code":""},{"path":"provocation.html","id":"reading-a-research-compendium","chapter":"1 Provocation","heading":"1.2 Reading a research compendium","text":"give idea end goal beginning reading one finished research compendiumgive idea end goal beginning reading one finished research compendiumcite Nust’s paper reading research compendiumcite Nust’s paper reading research compendiumIf running study written R using groundhog package reproducibility, may need run console enter “OK” console permit groundhog install packages study run.running study written R using groundhog package reproducibility, may need run console enter “OK” console permit groundhog install packages study run.","code":""},{"path":"provocation.html","id":"literature-for-reproduction-reanalysis-or-replication","chapter":"1 Provocation","heading":"1.3 Literature for reproduction, reanalysis, or replication","text":"First, choose study?\ncriteria choosing studies include:\n- intellectual merit study’s influence field study\n- broader impacts society environment, e.g. influence policy\n- feasibility based availability materials methods\n- desire learn teach study methods\n- concerns validity studyWe argue reproduction, reanalysis, replication starts assembling synthesizing complete information available original study design.\norder reproduce prior study, reproducing researchers students need comprehensive understanding original study.\nrecommend two approaches systematically approaching deep reading original study resulting comprehensive understanding digital resources link understanding original manuscript supplementary materials.\napproaches may undertaken parallel, include:Annotate original manuscript supplementary materialsDraw workflow plan original study","code":""},{"path":"provocation.html","id":"annotation","chapter":"1 Provocation","heading":"1.3.1 Annotation","text":"recommend annotating collaborative software environments, e.g. hypothes.Zotero.\nChoose system colors represent important components research design, including:Main hypotheses research questionsTheoretical conceptsInputs data observationsProcesses parameters processesComputational environmentResults, especially result can checked comparedYou may also apply tags indicate relationship individual hypotheses questions associated processes results indicate sequence processes overall research workflow.\napproach final draft workflow plan (see next subsection), recommend assigning unique identifier process tagging relevant sections original manuscript supplementary materials identifier, creating link original manuscript workflow plan.","code":""},{"path":"provocation.html","id":"workflow-plan","chapter":"1 Provocation","heading":"1.3.2 Workflow plan","text":"workflow visually illustrates research process three types symbols:Ovals represent inputs outputs databases, variables, observations, etc.Rectangles represent processes, algorithms, models, etc.Arrows illustrate sequence flow research designEarly drafts workflow plan may digital (e.g. digital whiteboard, simply text outline) analog tactile.\nmethods classes, Holler used stacks notecards, marker pens tape arrange workflows board.\neven printed results paper (e.g. tables, graphs, maps) use nodes analog board-based workflow graph.\nRemote classes research teams images digital whiteboard.recommend drawing final draft workflow plan specialized software task, e.g. draw.io ____.","code":""},{"path":"provocation.html","id":"data-at-the-provocation-phase","chapter":"1 Provocation","heading":"1.4 Data at the provocation phase","text":"Avoid biasing research plan interacting much data observations\nrecord / journal empirical observations / interactions data\n\nrecord / journal empirical observations / interactions dataview descriptive statistics data visualizationSave metadata","code":""},{"path":"provocation.html","id":"setting-up-research-compendium","chapter":"1 Provocation","heading":"1.5 Setting up research compendium","text":"","code":""},{"path":"provocation.html","id":"what-is-a-research-compendium-and-why-start-one-so-early","chapter":"1 Provocation","heading":"1.5.1 what is a research compendium, and why start one so early?","text":"","code":""},{"path":"provocation.html","id":"why-make-your-research-compendium-in-git","chapter":"1 Provocation","heading":"1.5.2 why make your research compendium in Git?","text":"experience, least XXX compelling reasons use form git version control research compendium.First, Git allows track, control, revert versions work, giving undo feature entire research project.\n’s powerful simple undo feature, Git also allows browse history versions, visualize changes version, selectively restore elements previous versions.\ncontrol exactly commit new versions describe purpose new versions.\nAdvanced users can even experiment branching multiple alternative versions project, e.g. sandbox thread alternative changes project without altering main version either discard failed changes decide integrate merge alternatives main project.Second, Git allows manage updates project research team, allowing team member commit changes sequentially, allowing team members check branch project work project subcomponent ready merging contributions back main project.\nresearch team members work way, provenance individual contributions team project recorded git commit metadata.\nresearch team uses service like GitHub GitLab host Git repository, research team access online management collaboration tools linked repository managing, tracking, communicating research project.Third, Git services providing servers Git (e.g. GitHub GitLab) make easy share projects researchers computational environments.\nresearch compendium can shared researchers via URL link cloning repository new computer manually downloading compressed zip archive file whole compendium.\ncompendium can also cloned new computational environment, e.g. RStudio Server, JupyterHub Server, high performance computing (HPC) service, Docker container.\nmovement full research compendium computational environments essential component computationally-intensive research computational reproducibility.Fourth, Git maintains history commits versions project, allows researcher passively record full provenance study’s development revision time, including information changes made, , , reasons.\nadds transparency revision process, e.g. making explicit research changed peer review member research team contributed.Fifth, GitHub GitLab can integrated digital archives open science, e.g. Open Science Foundation Figshare.\nalso support web services researchers may publish webpages findings directly within research compendiumFinally, Git highly compatible open science paradigm research research projects become “living papers” may updated time original authors, editors, peer reviewers, students.\nresearchers may easily fork new versions project purpose either making proposing changes original research form pull request, developing project new metascience study maintaining formal link original study purposes receiving updates tracking provenance research designs.","code":""},{"path":"provocation.html","id":"create-new-git-repository-based-on-our-template","chapter":"1 Provocation","heading":"1.5.3 Create new Git repository based on our template","text":"public / private statuschanges tracked commitsOrientation template structure / file system\ntop-level readme\nlicense\nMarkdown language\nmetadata\ndocs / reports\ntop-level readmelicenseMarkdown languagemetadatadocs / reportscommitting changes templateRecommended prefixes: / RPl / RPrChoose appropriate LICENSE file work","code":""},{"path":"provocation.html","id":"conclusion","chapter":"1 Provocation","heading":"1.6 Conclusion","text":"conclusion provocation phase, :Specific research questionConnect research question literature archetypical research designSet template research compendium","code":""},{"path":"ideation-and-research-design.html","id":"ideation-and-research-design","chapter":"2 Ideation and Research Design","heading":"2 Ideation and Research Design","text":"provocation phase, already developed specific research question, chose archetypical research design, set research compendium.Now time develop research plan!Remember, can amend research plan later.\ncan even embargo research plan git repository now making public later.\npoint start increasing transparency provenance research project now, can made public later.","code":""},{"path":"ideation-and-research-design.html","id":"develop-your-research-plan","chapter":"2 Ideation and Research Design","heading":"2.1 Develop your Research Plan","text":"already time translate specific research question archetypical research design, specific research plan.","code":""},{"path":"ideation-and-research-design.html","id":"reproduction-studies","chapter":"2 Ideation and Research Design","heading":"2.1.1 Reproduction studies","text":"","code":""},{"path":"ideation-and-research-design.html","id":"reanalysis-studies","chapter":"2 Ideation and Research Design","heading":"2.1.2 Reanalysis studies","text":"","code":""},{"path":"ideation-and-research-design.html","id":"replication-studies","chapter":"2 Ideation and Research Design","heading":"2.1.3 Replication studies","text":"","code":""},{"path":"ideation-and-research-design.html","id":"original-studies","chapter":"2 Ideation and Research Design","heading":"2.1.4 Original studies","text":"","code":""},{"path":"ideation-and-research-design.html","id":"project-metadata-front-matter-for-your-study","chapter":"2 Ideation and Research Design","heading":"2.2 Project metadata: front matter for your study","text":"Every journal article book starts front matter, essentially metadata publication, including citation attribution, copyright license, distribution, .\nOpen science starts making research project findable, require specifying standard metadata describing research project.\ntake time describe project metadata, likely find continue reuse information research throughout full life cycle.\ncoincidence, many publishers repositories adopted DUBLIN Core standards https://www.dublincore.org/specifications/dublin-core/ describing research artifacts.\nTherefore, never early create working draft project metadata top readme file research compendium.\ninformation transferred analysis plans research reports.research designs may multiple subcomponents different spatio-temporal characteristics.\nHowever, project-level metadata, simply report one -encompassing set spatio-temporal coverage metadata inclusive subcomponents finest resolution.\nresearch designs may replication study plans alter prior study’s spatio-temporal characteristics, case project-level metadata research compendium report planned spatio-temporal coverage replication study.Description: brief abstract research project.Contributors: names email contact information contributors. Note corresponding author asterisk *. corresponding author considered creator Dublin Core metadata. GitHub, may want explicitly link contributors’ GitHub profiles @ symbol, e.g. @josephholler. OSF, asked specify contributors’ permissions (administrator, read & write, read) whether bibliographic non-bibliographic contributor.Affiliated Institutions: List affiliations contributors one publications. OSF, field auto-populates registered institutions contributors benefit institutional subscriptions.Funding: applicable, include information one funding sources research project.\nFunder Name (NSF project, specific division directorate)\nAward Title\nAward info URI (web address)\nAward number\nFunder Name (NSF project, specific division directorate)Award TitleAward info URI (web address)Award numberDate created: date project startedDate modified: date recent revisionSubject: select controlled vocabularyTags: select keywords, separated commas. feature compatible GitHub, OSF, Journal Articles, Dublin Core element.Coverage (geographic): Specify geographic extent study. may place name link feature gazetteer like GeoNames OpenStreetMap, well known text (WKT) representation bounding box.Coverage (temporal): Specify temporal extent study—.e. range time represented data observations.Relation: Identifier links related research elements, e.g. OSF repository, preprints,Rights: Maintain link license file also list license type .Resource type: overall research compendium Collection eventually include specific subcomponents, e.g. Preprint, JournalArticle. Dublin Core maintains list resource types: https://www.dublincore.org/specifications/dublin-core/resource-typelist/ OSF: https://help.osf.io/article/570-resource-types--osfResource language: likely EnglishConforms : Conforms research compendium template reproducible replicable human-environment geographical sciences https://hegsrr.github.com/HEGSRR-TemplateThe project metadata excluded just Dublin Core elements:\n- Title implied first-level header Markdown document.\n- Creator implied contributor noted corresponding author history Git commits.\n- Publisher likely include multiple entities repository linked services like GitHub, GitLab, OSF, Figshare, digital Git repositories archives. Publisher implied service service hosted.\n- Format excluded research compendium collection contains digital files many different formats.metadata also includes elements beyond 15 core elements:\n- Coverage explicitly subdivided geographic temporal coverages.\n- Funding added compatibility OSF fulfill requirements funding agencies.\n- Affiliated Institutions added compatibility OSF normally included ","code":""},{"path":"ideation-and-research-design.html","id":"create-an-osf-project","chapter":"2 Ideation and Research Design","heading":"2.3 Create an OSF project","text":"Open Science Foundation (OSF, https://osf.io) digital archive open science digital artifacts.\nrecommend creating umbrella OSF project mapping directly Git research compendium.First, create new project.\nMake project settings title description identical information compendium readme.md file.\nbest category value complete research compendium project.\nproject categories suitable specific project components, need register separately.Second, add additional contributors, unless developing project solo researcher.\ncontributor, choose level permissions (administer, read write, just read) check bibliographic contributor included citations work.Third, project License can set project home page (click project title top-left) Description.\nUse Add license link choose license.\nStodden (XXXX) suggests BSD 3-Clause “New”/“Revised” License computational open science research.\nchoose license choose “license”, full copyright protections implied impossible researchers re-use project content.Fourth, complete additional metadata.\ndescription field points data project settings description contributors data points data contributors menu.\naffiliated institutions controlled OSF institutional subscriptions, date created date modified automatically generated.leaves three metadata fields manage:\n- Resource information: Resource type set Collection research compendium composed multiple resource types data formats.\nResource language likely English, unless translated compendium template.\nproject subcomponents registered separately specific resource type classifications.\n- Funding/support information: funding fields match information compendium readme.md file.\n- Tags: match information compendium readme.md file.Fifth, connect OSF project GitHub repository.\n- Add-ons -> GitHub\n- Files -> add repository???\ncontinue work git repository push changes GitHub, OSF project automatically stay --date changes.\nresearch life cycle create OSF registrations, archive static version compendium time registration.Finally, projects Make Public option, OSF warns use ready contents truly public.\nready project public, can also generate DOI inclusion project Citation.\nAdditionally, can type bibtex get citations dropdown copy BibTex citation data OSF project.\nproject public DOI, may crosslink information GitHub repository:\n- Return compendium readme.md add OSF project DOI Related : section.\n- Update CITATION.cff file cite OSF Project DOI.","code":""},{"path":"ideation-and-research-design.html","id":"data-in-the-ideation-phase","chapter":"2 Ideation and Research Design","heading":"2.4 Data in the ideation phase","text":"phase research, avoid directly observing study data greatest extent can avoided.\npre-analysis plan require disclose experience engagement data potential biases engagement introduces research process.\nTherefore, larger discussion data management open science research compendiums next chapter Observation.\nstage, concerned researching potential secondary data sources inventing structure observation design primary data collected.\n, concerned phase metadata data acquire, create, analyze, data .\nrecommended save information data data/metadata folder, start populating data/data_metadata.csv tabular index data directories row data sources associated metadata files, possibly write preliminary code accessing data specialized packages application programming interfaces (APIs), including using APIs query save metadata.data_metadata.csv file may contain information data files yet exist\nphase research, may know specific paths names files create.\nHowever, want keep track different layers intend create acquire associated metadata files.\nTherefore, may create temporary working names name column, keep accurate list metadata files metadata column, nThe data_metadata.csv file tabular index data file project, including fields:path: path data folder, likely one : raw\\private, raw\\public, derived\\private derived\\publicname: file name, including extension. may refer individual tables relational databases (e.g. geopackages) appending | layer name, e.g. my_layer table my_geopackage.gpkg noted name: my_geopackage.gpkg|my_layermetadata: list metadata files data source, stored data\\metadata folder. may include ISO-191** FGDC standard XML files, data dictionaries, licenses attributions, user guides, webpage printouts, etc. Separate multiple files semicolons: ;.description: brief description dataset. data simulated, randomized, represents limited sample full research dataset, note limitations .many cases may document metadata data sources directly included repository either large, proprietary, contain confidential information.\ndata_metadata.csv file proscribe location types data raw\\private data sources need downloaded /acquired permission /funding derived\\private large confidential files created computational code scripts.Researchers strongly encouraged include additional metadata metadata folder.\ninformation procedures used create acquire data stored private directories maintained procedure_metadata.csv.Ideally, metadata documented FGDC ISO standards saved xml, json, yaml format. tools reading writing metadata include:USGS Metadata Wizard 2.0: https://www.usgs.gov/software/metadata-wizard-20MDEditor: https://www.mdeditor.org/GeoNetwork: https://geonetwork-opensource.org/R geometa: https://cran.r-project.org/web/packages/geometaPython pygeometa: https://pypi.org/project/pygeometa/Social science metadata may follow Data Documentation Initiative (DDI) Codebook: https://www.projecttier.org/tier-protocol/protocol-4-0/root/data/originaldata/metadata/metadataguide/ Project TIER provides good advice data metadata: https://www.projecttier.org/tier-protocol/protocol-4-0/root/data/originaldata/metadata/.","code":""},{"path":"ideation-and-research-design.html","id":"writing","chapter":"2 Ideation and Research Design","heading":"2.5 Writing","text":"Write plain text codenew sentence linestored Git repository version controloptions:\nnon-computational (markdown latex )\nRmarkdown computational notebook\nJupyter Python\nnon-computational (markdown latex )Rmarkdown computational notebookJupyter PythonWe need move toward pre-analysis plan, code, outputs, everything R markdown file Jupyter notebook.\nMarkdown, use knitr generate report https://yihui.org/knitr/\nJupyter, use stitch https://pystitch.github.io/knitr stitch run, report can saved reports folder.\ntime, researcher commit Version Git repository, continue revising main notebook / rmarkdown.\nreduce redundancies recording provenance data, research plan, code.","code":""},{"path":"ideation-and-research-design.html","id":"citing","chapter":"2 Ideation and Research Design","heading":"2.6 Citing","text":"Use BibTex managing citations integration Rmarkdown LaTeXNecessary cite literature, also software dataImportant give credit researchers developed software packages /data using citing preferred referenceGitHub repositories may .cff files information preferred citationsCitations versions paper work (e.g. preprint, compendium, data, code)citation package R https://ropensci.org/blog/2021/11/16/--cite-r--r-packages/Guide intergating Zotero RMarkdown: https://christopherjunk.netlify.app/blog/2019/02/25/zotero-rmarkdown/worcs package r supports distinguishing “essential” references “non-essential” references, full reference list can rendered preprint limited reference list can rendered journal article limitations number references words. See https://cjvanlissa.github.io/worcs/articles/citation.html","code":""},{"path":"ideation-and-research-design.html","id":"procedures","chapter":"2 Ideation and Research Design","heading":"2.7 Procedures","text":"Save methods procedures supporting documents procedures directory.Catalog procedures ordered table documenting code research procedure/protocol documents. Provide brief description purpose procedure piece code.Catalog files procedure_metadata.csvSee example table , modify table suit research design.path: path file directory, usually one code software code scripts, environment hardware/software computational environment, protocol non-code protocols likename: file name, including extensionpurpose: brief description purpose fileThe sequence procedures followed implied order table explicit pre-analysis plan post-analysis report.","code":""},{"path":"ideation-and-research-design.html","id":"environment","chapter":"2 Ideation and Research Design","heading":"2.7.1 Environment","text":"Store detailed information hardware software environment requirements procedures code .\nmay also document recipe container computational environment .directory specifically hardware software environments.\nContextual factors confounds human subjects research field research communicated protocol documents stored protocols subdirectory.imperative track versions software, software packages, dependencies research project.\nPackage versions change frequently, may even change working project.\nhighly recommend keeping one main list software packages versions requried project using list install load packages code document metadata computational environment.\nMany templates guides computational research suggest writing code series scripts, one phase research workflow.\ntaking approach, beware loading different sets packages different scripts without maintaining one comprehensive list required packages.users R, template code, minimum, saves environment information using sessionInfo() function.\nRmarkdown template includes code using groundhog package manage loading version R packages dependencies specific date.users Python, …","code":""},{"path":"ideation-and-research-design.html","id":"code","chapter":"2 Ideation and Research Design","heading":"2.7.2 Code","text":"Store computational code-based research procedures code subdirectory.","code":""},{"path":"ideation-and-research-design.html","id":"protocols","chapter":"2 Ideation and Research Design","heading":"2.7.3 Protocols","text":"Store non-computational protocols research procedures protocols subdirectory.store IRB protocol forms instruments procedures / protocolsthe research compendium part data management planread ahead dissemination phase considering privacy data management","code":""},{"path":"ideation-and-research-design.html","id":"pilot-study","chapter":"2 Ideation and Research Design","heading":"2.8 Pilot study","text":"research designs benefit pilot study, use limited set observations test revise () data collection instrument(s) test methodology limited set data.\nPilot studies specified analysis plan methodology disclosed Prior observations section plan.\ndata observations findings pilot study included complete study disseminated archived.\nTherefore, pilot study data materials may saved data/scratch directory temporary use.pilot study data go /scratch folder?","code":""},{"path":"ideation-and-research-design.html","id":"conclusion-1","chapter":"2 Ideation and Research Design","heading":"2.9 Conclusion","text":"developed archetypical research design specific registered research plan.\ndeveloped research compendium\nconnected research registration OSF GitHub","code":""},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"writing-an-analysis-plan-for-preregistration","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3 Writing an Analysis Plan for Preregistration","text":"Pre-analysis plan templates designed help researchers specify research design decisions susceptible p-hacking disciplines.\nfollows intuitively templates address research issues biomedical research, psychology, econometrics, disciplines forefront discovering addressing “replication crisis”.\ntemplates well suited experimental quasi-experimental research designs researcher significant control sampling observations.However, found pre-analysis plans human-environment geographical sciences related disciplines, many research designs integrate many different data sources different spatio-temporal supports.\nresearch designs require sophisticated methods involving many researcher decisions multiple threats validity: therefore require attention detail analysis plan preregistration.\ntime, recognize disciplines look geography comes time specify details (spatial) data sources, referring researchers Federal Geographic Data Committee (FGDC) ISO 191* series standards geographic metadata.\nFurthermore, highest standards reproducible research compendia research data archiving require documentation international standards.\nTherefore, adopted Dublin Core standard expanded detail coverage element describe spatio-temporal support overall project; adopted International Standards Organization (ISO) 19115 standard geographic information metadata describe spatio-temporal support individual data sources.next sections chapter guide steps preparing analysis plan preregistration, culminating instructions registering plan OSF.","code":""},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"study-metadata","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.1 Study metadata","text":"analysis plan begins title metadata project.\ncompleted root readme.md file research compendium, can probably copy metadata directly top analysis plan.\nredundancy necessary registered plan document contains necessary information independently research compendium.\nproject-level metadata also provides foundation analysis plan specifying spatio-temporal characteristics study, making explicit beginning target data support input data.\nPlease see instructions overarching metadata Ideation Chapter, Section X, see contingencies studies multiple sub-components replication studies .","code":""},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"studies-with-multiple-spatio-temporal-coverages","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.1.1 Studies with multiple spatio-temporal coverages","text":"studies may contain subcomponents different spatio-temporal characteristics, may contain multi-level models.\ncase, need enumerate different metadata values spatial /temporal characteristics vary across subcomponents study.\nlist study metadata contain overarching metadata study (.e. coverages inclusive subcomponents resolutions ranges smallest largest).main metadata fields, make hierarchical list table study subcomponents metadata characteristics vary across .example, study Social Vulnerability Indices across different spatial extents, overarching metadata may :\n- Spatial Coverage: Continental United States (spatial extent encompasses subcomponents study)\n- Spatial Resolution: Counties EPA Regions (range smallest resolution enumeration units largest)\n- Spatial Reference System: ESRI:102003 (spatial reference system overarching spatial coverage)\n- Temporal Coverage: 2017-2022 (temporal extent encompasses subcomponents study)\n- Temporal Resolution: 5-year estimate (example one resolution therefore require range)spatial coverage, resolution, reference system can shown vary across study subcomponents adding statement explaining subcomponents, followed hierarchical list. example:table may used place hierarchical list.\nexample:","code":"There are three subcomponents to the studies with varying spatial coverage, resolution, and reference systems.\nThe subcomponents are named: Macro level, Meso level, and Micro level.\n\n- Macro Level Analysis\n  - `Spatial Coverage`: Continental United States\n  - `Spatial Resolution`: EPA Regions (aggregations of states)\n  - `Spatial Reference System`: ESRI:102003\n- Meso Level Analysis\n  - `Spatial Coverage`: EPA Region 4\n  - `Spatial Resolution`: States (first admin level)\n  - `Spatial Reference System`: ESRI:102003\n- Micro Level Analysis\n  - `Spatial Coverage`: Florida\n  - `Spatial Resolution`: Counties (second admin level)\n  - `Spatial Reference System`: EPSG:3086|                          | Macro Level    | Meso Level   | Micro Level    |\n| :----------------------: | :------------: | :----------: | :------------: |\n| Spatial Coverage         | Continental US | EPA Region 4 | Florida        |\n| Spatial Resolution       | EPA Regions    | States ADM_1 | Counties ADM_2 |\n| Spatial Reference System | ESRI:102003    | ESRI:102003  | EPSG:3086      |"},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"replication-studies-with-different-spatio-temporal-coverages","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.1.2 Replication studies with different spatio-temporal coverages","text":"study replication prior study different spatial temporal characteristics prior study, first block metadata describe replication study spatio-temporal characteristics.\nFollowing replication study metadata prior Study design section, add sub-section original (prior) study spatio-temporal characteristics.\nexample:","code":"#### Original study spatio-temporal metadata\n\n- `Spatial Coverage`: extent of original study\n- `Spatial Resolution`: resolution of original study\n- `Spatial Reference System`: spatial reference system of original study\n- `Temporal Coverage`: temporal extent of original study\n- `Temporal Resolution`: temporal resolution of original study"},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"study-design","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.2 Study design","text":"section describes archetypal study design used specifies clear hypotheses research questions.Describe study relates prior literature, e.g. original study metascience study (one : meta-analysis study, reproduction study, reanalysis study, replication study)?Also describe original study archetype, e.g. observational, experimental, quasi-experimental, exploratory?Enumerate specific hypotheses tested research questions investigated , specify type method, statistical test model used hypothesis question.\nexample:study reproduction, reanalysis, replication, meta-analysis, use prefixes differentiate original study hypothesis meta-science hypothesis.\nrecommend following prefixes:-H: original hypothesisMA-H: meta-analysis hypothesisRPr-H: reproduction hypothesisRA-H: reanalysis hypothesisRPl-H: replication hypothesisenumerate original study hypotheses analyzed type test model used hypothesis.\ncan numbered prefix -H “Original Hypothesis”, e.g.original study used Spearman’s Rho rank correlation test -H1.","code":"> H1: Hypothesis number one\n\n`H1` will be tested with a linear regression model.> OR-H1: Median home prices of census tracts are dependent upon the distance from the central business district (CBD) in Chicago, Illinois.\n\nOR-H1 was tested with a linear regression model having median home prices as the dependent variable and distance between the central business district and the census tract centroid as the independent variable.\n\n> RPl-H1: The coefficient of distance from CBD in Buffalo, New York will have equivalent direction and magnitude to the coefficient of distance from the CBD in Chicago, Illinois.\n\nRPl-H1 will be tested by substituting data for Chicago, Illinois with data for Buffalo, New York and repeating the linear regression of OR-H1."},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"planned-deviations-of-metascience-studies","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.3 Planned deviations of metascience studies","text":"study metascience study (.e. reproduction, reanalysis, replication), analysis plan simply articulated best understanding prior study.\nHowever, different degrees, metascience study may intend alter parameters prior study.\nalterations labelled planned deviation include rationale deviation.\nCategorize deviations reproduction aim deviation still reproduce original methodology original results.\nCategorize deviations reanalysis aim alter methodological parameter study order compare results, e.g. test sensitivity, uncertainty, robustness.\nCategorize deviations replication aim alter spatial-temporal coverage study otherwise repeat study methodology new data/observations.example, recent reproduction study contained planned deviation expectation altering data, methods, results:","code":"**Planned deviation for reproduction**: Although the original study used SPSS and SaTScan for analysis, we will attempt to reproduce the study using R and its spatialepi and geepack packages for equivalent analysis using an open source software environment."},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"preregister-your-analysis-plan-on-osf","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.4 Preregister your analysis plan on OSF","text":"Open Science Foundation ecosystem open science infrastructure, registration means make archive permanent record research project one moment time.\nregister analysis plan report associated OSF project, copy entire project made accompany registration.\npreregistration registration research prior data collection analysis.ready preregister plan, remember update Date modified field plan project readme.md front matter.ready register analysis plan, log OSF navigate project.\nOpen Registrations menu begin New registration.OSF contains several registration templates.\nuse template, select Open-Ended Registration.Even open-ended registration requires standard metadata.\nFortunately, OSF pulls metadata umbrella project, including title, description, contributors, category, license.Curiously, first opportunity enter subject, likely one :\n- Social Behavioral Sciences  Geography  (Geographic Information Sciences, Human Geography, Nature Society Relations, Geography, Physical Environmental Geography, Remote Sensing, Spatial Science)pro\n- Social Behavioral Sciences  Environmental Studies  …Following Metadata, Summary short description file uploading, simply describe pre-analysis plan registration.\nupdating prior plan, major updates rationale noted summary.Upload pre-analysis plan pdf file supplementary file.Finally, Review registration confirm accuracy moving Register plan.\nstage option make publication public immediately enter registration embargo specified end date.\nembargo option means registration locked Submit , remain private embargo date, made public.submitted registration deleted revoked even embargo: recourse errors registration make new registration supersede prior one.\nadmin contributors registration option revoke registration first 48 hours submission.registered pre-analysis plan, remember copy DOI add DOI link Related section compendium readme.md file.Note: need project associated registration identify specific files research compendium specific types resources, prior registration can navigate file edit file-level metadata. See instructions: https://help.osf.io/article/569-add-metadata---osf-file","code":""},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"amending-the-analysis-plan-registration","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.5 Amending the analysis plan registration","text":"registered, analysis plan locked permanent record research plan particular time.\nHowever, plans change!\nchanges plans pre-analysis registration post-analysis report must documented unplanned deviations results stemming changes may interpreted appropriately.\nKeeping mind purpose preregistration reduce increase transparency purpose reducing bias p-hacking research process, revised preregistration useful researcher(s), based prior observations data, can still specify relatively unbiased analysis plan.\nanalysis plan amended fly based reactions data observations, better record amendments unplanned deviations final report, rather falsely claim changes unbiased amendments analysis plan prior study.\nneed make significant changes analysis plan amended plan already substantially biased prior analyses data observations, time amend analysis plan update preregistration.case need amend analysis plan, may edit section prior plan add explanation changes.\nsure update Date modified field study metadata.recommend adding second-level section titled “Rationale analysis plan update” end analysis plan, immediately following Integrity Statement section.\nnew section begin statement including plan version prior registration DOI link, followed rationale update one paragraphs.Also include paragraph discussing change prior observations data since prior preregistration, statement change prior observations data.","code":"### Rationale for updated report\n\nThis is the second version of the analysis plan preregistration, superseding the first version, registered at https://doi.org/10.17605/OSF.IO/647EX on July 22, 2022.\nThe rationale for this update is...\n\nOur prior observations of the data have changed/not changed.\nSince the prior version, we have now..."},{"path":"writing-an-analysis-plan-for-preregistration.html","id":"resources","chapter":"3 Writing an Analysis Plan for Preregistration","heading":"3.6 Resources","text":"Dublin Core:\nISO 19115:\nOSF Preregistration resources: https://www.cos.io/initiatives/prereg\nGuide create registrations: https://help.osf.io/article/345-create-registrations","code":""},{"path":"data-observation-and-curation.html","id":"data-observation-and-curation","chapter":"4 Data Observation and Curation","heading":"4 Data Observation and Curation","text":"","code":""},{"path":"data-observation-and-curation.html","id":"data-management","chapter":"4 Data Observation and Curation","heading":"4.1 Data Management","text":"Store research data data subdirectories. recommended raw data altered downloaded collected. Maintaining separate raw data file facilitates reproducibility preserving common point analytical origin. similarly recommended whenever possible data processing, transformation, manipulation completed code practice facilitates re-analysis reduces opportunities confusion.Complete data_metadata.csv file indexing raw derived data file, including fields:path: path data folder, likely one : raw\\private, raw\\public, derived\\private derived\\publicname: file name, including extensionmetadata: list metadata files data source, stored data\\metadata folder. may include ISO-191** FGDC standard XML files, data dictionaries, licenses attributions, user guides, webpage printouts, etc.status: may included data included repository create acquire data must created acquired, derived data generated code data files, simulated data replaces true research data simulated data due confidentiality legal constraints, unavailable data shared reproduced way.description: brief description dataset.Researchers strongly encouraged include additional metadata metadata folder.\ninformation procedures used create data ‘status = derive’ maintained procedure_metadata.csv.See metadata engaging data section previous chapter.","code":""},{"path":"data-observation-and-curation.html","id":"collect-preliminary-data","chapter":"4 Data Observation and Curation","heading":"4.2 Collect preliminary data","text":"metadata!code/scripts data acquisitiondirectory structure data\nscratch (tracked)\nraw / public\nraw / private (tracked)\nderived / public\nderived / private (tracked)\nscratch (tracked)raw / publicraw / private (tracked)derived / publicderived / private (tracked)file size limits GitHub / GitLab","code":""},{"path":"data-observation-and-curation.html","id":"raw-private-data","chapter":"4 Data Observation and Curation","heading":"4.2.1 Raw private data","text":"Store raw data folder collected downloaded data publicly redistributed. example, data versioning sharing restricted large file sizes, licensing, ethics, privacy, confidentiality. Best practices include code automate process downloading simulating raw private data first step methods, include instructions accessing private restricted-access data.folder ignored Git versioning exception readme.md file following lines .gitignore","code":"# Ignore contents of private folder, with the exception of its readme file\nprivate/**\n!private/readme.md"},{"path":"data-observation-and-curation.html","id":"caution-dealing-with-large-files","chapter":"4 Data Observation and Curation","heading":"4.2.2 Caution: Dealing with large files","text":"GitHub store files larger 100mbThese placed private directories tracked Git uploaded GitHubOSF Figshare allow larger file storage options, may store large files services write code downloading files private directories analysis runs. Significant data sources registered DOI links.Git GitHub designed track store large files 100 mb.accidentally attempted commit changes large files, … INSTRUCTIONS","code":""},{"path":"data-observation-and-curation.html","id":"updating-the-analysis-plan","chapter":"4 Data Observation and Curation","heading":"4.3 Updating the analysis plan","text":"likely encounter unexpected challenges need change original, pre-analysis registration plan.\nnormal: just diligent updating analysis plan, cataloguing deviations original plan, committing changes repository.Document unplanned deviations occur analysis plan.\nstudy metascience study, categorize unplanned deviations reproduction aim deviation still reproduce original methodology original results.\nCategorize deviations reanalysis aim alter methodological parameter study compare results, e.g. test sensitivity, uncertainty, robustness.\nCategorize deviations replication aim alter spatial-temporal coverage study otherwise repeat study methodology new data/observations.full transparency, document rationale form deviation.","code":""},{"path":"analysis-and-validation.html","id":"analysis-and-validation","chapter":"5 Analysis and Validation","heading":"5 Analysis and Validation","text":"","code":""},{"path":"analysis-and-validation.html","id":"changes-to-the-pre-analysis-plan-registration","chapter":"5 Analysis and Validation","heading":"5.1 Changes to the pre-analysis plan registration","text":"Researchers likely encounter need deviate registered pre-analysis plan.save version text file used write register pre-analysis planmajor changes plan may require updating document, rendering new PDF updating registration OSF.QUESTION: change registered pre-analysis plan big enough require update OSF?\n- uncertainty ambiguity contingencies already articulated pre-analysis plan, need update plan.\n- alterations pre-analysis plan may ultimately impact interpretation claims made research, changes registered OSF.parallel, changes (minor major) identified bold text subheadings narrative analytical plan research progresses. suggested labels changes include:update preanalysis plan","code":""},{"path":"analysis-and-validation.html","id":"coding-and-code-style","chapter":"5 Analysis and Validation","heading":"5.2 Coding and Code style","text":"R follow Tidyverse style: https://style.tidyverse.org/ two great addins:\n- stylr formats code https://styler.r-lib.org/\n- lintr checks code formatting: https://github.com/jimhester/lintrPython follow PEP 8 Style: https://www.python.org/dev/peps/pep-0008/","code":""},{"path":"analysis-and-validation.html","id":"intermediary-outputs","chapter":"5 Analysis and Validation","heading":"5.3 Intermediary outputs","text":"possible, unwise, encode entire workflow computational notebook without saving intermediary results.\nintermediary results saved, , ?\nleast five major situations saving data results paramount increasing reproducibility study:Immediately following code download create data can redistributed, data saved raw\\public folder.soon confidential, proprietary, large data sources processed enough redistribute, data saved derived\\public folder.computationally intensive processes, results saved derived\\public folder.external software process used manipulate data, data saved derived\\public folder just prior external process just external process. process outside main computational notebook documented notebook narrative /separate procedure code protocol files.randomization stochastic model applied analysis, results random aspect analysis saved derived\\public folder.computational notebook include code save (re)load intermediary data files, recommended practice :\n1. save formats open standards without encoding data object name\n2. read functions assign data object nameRecommended open standard file types include .csv, .json .gpkg.\nexample, working R, best use .RDS file type store individual data objects without data object name rather relying .RData files potentially encompassing multiple data objects encoding names.\nSaving data files agnostic object name R Python adds clarity provenance data manipulated research workflow allows researchers modify code compare results replications reanalyses.Researchers can encode data saving loading procedures separate code blocks modify code chunk options optimal reproducibiliy.\nexample, necessary query API every time computational notebook run: code chunk API query can set eval = FALSE code chunk load resulting data can set eval = TRUE.See RMarkdown code chunk options: https://rpubs.com/Lingling912/870659 Jupyter code block options","code":""},{"path":"analysis-and-validation.html","id":"function-parameters","chapter":"5 Analysis and Validation","heading":"5.4 Function parameters","text":"may convenient use default parameters functions coding script research project, practice makes difficult researchers understand code may vulnerable changes required packages time.\nparameter important, best practice include function call.\nexample, functions classifying continuous data purpose choropleth mapping may contain default number classes, helpful choose declare default explicitly research code rather requiring others look function defaults.\nresult declaring parameters intentional research design legible code.","code":""},{"path":"analysis-and-validation.html","id":"store-publication-ready-outputs-in-the-results-directory","chapter":"5 Analysis and Validation","heading":"5.5 Store publication-ready outputs in the results directory","text":"Store publication-ready final research outputs, e.g. figures, tables, media publications presentations results directory.Although types results ideally embedded outputs computational notebooks, researchers also find convenient share repurpose individual figures tables blogs, web designs, presentations, .\nTherefore, makes sense add final block code computational studies output important results separate files.\n, complete results_metadata.csv file indexing results file, including fields:path: path results folder, e.g., figures, , tablesname: file namedescription: brief description figure titleWise researchers may even edit results_metadata.csv file computational notebook!","code":""},{"path":"dissemination.html","id":"dissemination","chapter":"6 Dissemination","heading":"6 Dissemination","text":"Export work LaTeX, using appropriate template intended publicationRegister preprint workSubmit peer reviewTrack versions using GitHubinclude citations open science data software study, e.g. using citation() function R","code":""},{"path":"preservation.html","id":"preservation","chapter":"7 Preservation","heading":"7 Preservation","text":"","code":""},{"path":"preservation.html","id":"license","chapter":"7 Preservation","heading":"7.1 LICENSE","text":"Verify used appropriate open access license LICENSE fileEither provocation phase, , discuss reasons BSD 3.0 license.","code":""},{"path":"preservation.html","id":"citation-1","chapter":"7 Preservation","heading":"7.2 CITATION","text":"Verify CITATION.cff file GitHub appropriate citation information “cite repository” feature correctly generates appropriate citation work.https://docs.github.com/en/github/creating-cloning--archiving-repositories/creating--repository--github/-citation-files","code":""},{"path":"preservation.html","id":"versioning","chapter":"7 Preservation","heading":"7.3 versioning","text":"Commit final version tagged release GitHubRegister final version OSFlarge files can uploaded OSF attatched release GitHub","code":""},{"path":"reproduction.html","id":"reproduction","chapter":"8 Reproduction","heading":"8 Reproduction","text":"whole concept behind open science researchers students able reproduce,\nreplicate, extend scientific studies published.\nchapter devoted epilogue: engage published open science study.\nrepurposing scientific study normally start reproducing original study results - process differ depending computational environment original materials.\nhope standardizing research template, eased work reproducing study.chapter provides guidance reproducing study published executable research compendium.\nfirst review procedures studies conforming version 2.0 greater HEGSRR-Template.\n, provide options studies published formats.\nscenario, review options two commonly used computational notebook formats:\nR R Markdown, Python Jupyter.","code":""},{"path":"reproduction.html","id":"our-template","chapter":"8 Reproduction","heading":"8.1 Our template","text":"reproducibility template, can found HEGSRR/HEGSRR-Template GitHub, designed reduce common frustrations trying execute compendium computational geography.\ntips setting computational environments equivalent used template.Refer procedure/environment/ folder README.md may contain quick start instructions.","code":""},{"path":"reproduction.html","id":"r","chapter":"8 Reproduction","heading":"8.1.1 R","text":"R “free software environment statistical computing graphics”.\ninstall R, navigate https://cloud.r-project.org/.\nAdditionally, install RStudio (https://posit.co/downloads/),\npopular IDE (Integrated development environment) R.\n1Those looking “cloud” solution may want try Posit Cloud.","code":""},{"path":"reproduction.html","id":"the-groundhog-package","chapter":"8 Reproduction","heading":"8.1.1.1 The groundhog package","text":"template (HEGSRR/HEGSRR-Template) uses package groundhog (CredibilityLab/groundhog) achieve reproducibility R scripts.Given date list packages needed, groundhog can retrieve --date version R packages date.recover list packages, relevant .Rmd file, look references groundhog.\ntypically code chunk deals setup tasks.recommended groundhog’s developers, sensible first step change specified groundhog.day reasonably recent date - date corresponding version R, recent date last week., can execute main function, groundhog.library().\nDepending date selected, may need install another version R --date date.\nexpected, changes R may impact computational results well.\nmay also need give groundhog permission install packages certain folder; template, set data/scratch/groundhog/.code functions expected, set!\n, can amend groundhog day back original one;\ninstalling correct version R, groundhog proceed install packages date.See article Changing R version RStudio Desktop IDE tell RStudio use specific version R.","code":""},{"path":"reproduction.html","id":"python","chapter":"8 Reproduction","heading":"8.1.2 Python","text":"Installing Python locally can somewhat complicated.\naddition Python, Jupyter also needed interactive notebooks.\nTutorials found Internet also frequently mention conda, package manager;\nadditional packages ipykernel nb_conda_kernels may also needed.alternative, many platforms offer “cloud” notebook requires minimal setup.\nAdditional benefits cloud notebooks may include:Disposable environment (see Disposable environment section )hardware requirement userAccess premium hardware computational power, usually costShare collaborate others","code":""},{"path":"reproduction.html","id":"disposable-environment","chapter":"8 Reproduction","heading":"8.1.2.1 Disposable environment","text":"Python package manager, pip, installs packages global library.\nmay lead conflicts, different projects require different versions package.Fortunately, machine disposable never runs one project, one worry managing packages - one can simply install--forget.\nOne example “disposable environment” Google Colab, one given fresh machine whenever one connects Jupyter runtime.\nAnother example https://mybinder.org/, provides free virtual machine repository Jupyter notebooks.","code":""},{"path":"reproduction.html","id":"package-management","chapter":"8 Reproduction","heading":"8.1.2.2 Package management","text":"However, working personal laptop, departmental machine, another non-disposable environment, keeping system tidy desirable.case, installing packages listed inside requirements.txt, “virtual environment” created.\nvirtual environment, changes made system-level.\nPython’s venv conda two common approaches.tutorial website RealPython walks using, well motivates, venv: Python Virtual Environments: Primer","code":""},{"path":"reproduction.html","id":"the-pipenv-package","chapter":"8 Reproduction","heading":"8.1.2.3 The pipenv package","text":"Python, template (HEGSRR/HEGSRR-Template) may used package pipenv virtual environment.\nindicated Pipfile Pipfile.lock file, found procedure/environment/ folder.recover computational environment, first install pipenv:, navigate procedure/environment/ folder.\nPipfile Pipfile.lock file present, run:Pipfile.lock file present, run:","code":"!pip install --user pipenv!cd ../environment\n!pipenv sync!cd ../environment\n!pipenv install\n!pipenv sync"},{"path":"reproduction.html","id":"the-pigar-package","chapter":"8 Reproduction","heading":"8.1.2.4 The pigar package","text":"Pipfile Pipfile.lock file found procedure/environment/,\nproject question may used pigar (damnever/pigar) generate requirements.txt,\nlist packages needed.using disposable environment, simply run following code (Jupyter) install required packages:non-disposable environments, recommend installing pipenv virtual environments:, utilize pipenv import requirements file:","code":"!pip install -r /path/to/requirements.txt!pip install --user pipenv!pipenv install -r path/to/requirements.txt"},{"path":"reproduction.html","id":"other-compendiums","chapter":"8 Reproduction","heading":"8.2 Other compendiums","text":"general tips recover research compendium one might find Internet.","code":""},{"path":"reproduction.html","id":"r-1","chapter":"8 Reproduction","heading":"8.2.1 R","text":"encounter list packages respective versions, install versions manually.\ncan remotes::install_version() function documented .However, older version packages CRAN usually available “source” form, immediately usable “binary” form.\nmeans need R development environment installed package compiled source binary.\ncan check running devtools::has_devel().Windows, “development environment” RTools;\nMacOS process slightly complicated.One complication packages often require system-level dependencies.\ndependencies additional software always available, consistent, across different machines.\nThus, installing “source” packages often prone failure.","code":""},{"path":"reproduction.html","id":"recovering-with-groundhog","chapter":"8 Reproduction","heading":"8.2.1.1 Recovering with groundhog","text":"Fortunately, groundhog package (CredibilityLab/groundhog) can used attempt recovery computational environment, especially original versions unknown.Given list packages, next step guess “groundhog day” packages --date.\ngood guess research question conducted, date publication.\ndate (packages function correctly) identified, date can recorded, reproducible compedium produced.","code":""},{"path":"reproduction.html","id":"the-renv-package","chapter":"8 Reproduction","heading":"8.2.1.2 The renv package","text":"Analogous venv Python, renv records versions R packages certain project, isolates packages separate virtual environment.Per documentation, project renv contain renv directory, well renv.lock file.\nopening project, renv automatically activate prompt run renv::restore(), restores virtual environment.Note renv usually install “source” recovering, often fail.\nSee renv’s Caveats page details.","code":""},{"path":"reproduction.html","id":"python-1","chapter":"8 Reproduction","heading":"8.2.2 Python","text":"Projects using virtual environments (venv, virtualenv, conda, Poetry, etc.) usually least mention method used.\nOne can also look hints folder structure, example venv folder.\nparticluar solution located, documentation restoring environment can readily found online.","code":""},{"path":"reproduction.html","id":"manually-create-requirements.txt","chapter":"8 Reproduction","heading":"8.2.2.1 Manually create requirements.txt","text":"encounter list package names Python, possible convert list reproducible requirements.txt file.\nSimply find package version works, record requirements file.example requirements file.Using package scipy example:scipy: install latest version Python Package Index (PyPI).scipy == 1.9.1: install version 1.9.1 PyPI.scipy == 1.9.*: install latest version starts 1.9.1. installs 1.9.3, unless scipy decides release version 1.9.4.ensure repeatability, best practice specify exact version packages; called “version pinning”.","code":""},{"path":"reproduction.html","id":"docker","chapter":"8 Reproduction","heading":"8.2.3 Docker","text":"may encounter compedium form Docker container Dockerfile.\ncase, need run Docker.Docker software can package software “containers”.\ncontainers run inside virtual machine, within “host” machine runs Docker program.Docker containers can distributed directly, usually “container registry” can “pull” , occasionally large file.can also come form Dockerfile, “recipe” producing Docker container.\nDockerfile need accompanied files (data, software, etc.) Docker uses “ingredients” produce Docker container.Installing Docker (Desktop) Windows MacOS possible, complications caveats exist.\npreferred way use Docker (Server) server running supported Linux distribution.Dockerfile contains instructions create (“build”) Docker container; run docker build turn project--Dockerfile container.\nAlternatively, Docker container may already built; case, docker pull container onto host machine.\ncontainer, can use docker run execute container.Note Docker images essentially virtual machines inside system, usually possible directly access virtual machine.\nOften, communication happens browser.\nexample, Docker image may run RStudio Server (JupyterLab), case can access service browser.","code":""},{"path":"reproduction.html","id":"cloud-services","chapter":"8 Reproduction","heading":"8.2.3.1 Cloud services","text":"Alternatively, can utilize online service run Docker.Many platforms offer “virtual machines” run Linux distributions, can install run Docker inside machines.\nAnother commonly-seen approach platform run Docker .using cloud services, especially “virtual machines”, important note risk someone hacking cloud machine, possibly anywhere world.\nTherefore, using cloud service, desirable follow common best practices (e.g. use strong password, use SSH keys, set firewall), take extra precautions guard unauthorized access machine.","code":""},{"path":"reproduction.html","id":"acknowledgement","chapter":"8 Reproduction","heading":"8.3 Acknowledgement","text":"Special thanks Yifei Luo contributions chapter.","code":""}]
